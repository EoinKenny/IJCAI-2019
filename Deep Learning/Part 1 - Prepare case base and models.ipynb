{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN-CBR Twin-System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data & Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "oh_y_train = to_categorical(y_train)\n",
    "oh_y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Normalise the data \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if K.image_data_format() == 'channels_first':\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "input_shape = (1, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Keras CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 156s 3ms/step - loss: 0.4219 - acc: 0.8635 - val_loss: 0.0662 - val_acc: 0.9797\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0889 - acc: 0.9740 - val_loss: 0.0377 - val_acc: 0.9886\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 156s 3ms/step - loss: 0.0631 - acc: 0.9812 - val_loss: 0.0350 - val_acc: 0.9881\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 157s 3ms/step - loss: 0.0490 - acc: 0.9862 - val_loss: 0.0416 - val_acc: 0.9864\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0412 - acc: 0.9877 - val_loss: 0.0316 - val_acc: 0.9905\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0363 - acc: 0.9896 - val_loss: 0.0264 - val_acc: 0.9917\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 145s 2ms/step - loss: 0.0305 - acc: 0.9910 - val_loss: 0.0248 - val_acc: 0.9921\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 146s 2ms/step - loss: 0.0260 - acc: 0.9922 - val_loss: 0.0241 - val_acc: 0.9925\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 146s 2ms/step - loss: 0.0241 - acc: 0.9926 - val_loss: 0.0251 - val_acc: 0.9923\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 145s 2ms/step - loss: 0.0210 - acc: 0.9941 - val_loss: 0.0224 - val_acc: 0.9931\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 145s 2ms/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0305 - val_acc: 0.9911\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 141s 2ms/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0261 - val_acc: 0.9925\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0146 - acc: 0.9954 - val_loss: 0.0236 - val_acc: 0.9935\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.0215 - val_acc: 0.9933\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0250 - val_acc: 0.9926\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0236 - val_acc: 0.9926\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 139s 2ms/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.0334 - val_acc: 0.9912\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 138s 2ms/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0245 - val_acc: 0.9931\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 145s 2ms/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0240 - val_acc: 0.9939\n",
      "60000/60000 [==============================] - 103s 2ms/step\n",
      "Training Set: \n",
      "acc: 99.93%\n",
      "10000/10000 [==============================] - 17s 2ms/step\n",
      "Test Set: \n",
      "acc: 99.39%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Cell 1 - 1x28x28\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), padding='same', data_format='channels_first'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
    "\n",
    "# Cell 2 - 32x4x14\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(16, 14, 14), padding='same', data_format='channels_first'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
    "\n",
    "# Output - 64x7x7\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, oh_y_train,\n",
    "          batch_size=256,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, oh_y_test))\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_train, oh_y_train)\n",
    "print(\"Training Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(X_test, oh_y_test)\n",
    "print(\"Test Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Normal k-NN:\n",
    "Just for a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
    "knn_X_test = X_test.reshape(X_test.shape[0], 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train final k-NN \n",
    "knn_clf = KNeighborsClassifier(n_neighbors=1, algorithm=\"brute\") \n",
    "knn_clf.fit(knn_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy Test: 0.9691\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy on this particular split to make sure that it is not too far removed from k-fold.\n",
    "knn_predictions_test = knn_clf.predict(knn_X_test)\n",
    "print(\"k-NN Accuracy Test:\", accuracy_score(y_test, knn_predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement: 0.9691\n"
     ]
    }
   ],
   "source": [
    "nn_pred = model.predict_classes(X_test)\n",
    "\n",
    "right = 0\n",
    "for i in range(len(nn_pred)):\n",
    "    if knn_predictions_test[i] == nn_pred[i]:\n",
    "        right += 1\n",
    "print(\"Agreement:\", right/len(nn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 973,    1,    1,    0,    0,    1,    3,    1,    0,    0],\n",
       "       [   0, 1129,    3,    0,    1,    1,    1,    0,    0,    0],\n",
       "       [   7,    6,  992,    5,    1,    0,    2,   16,    3,    0],\n",
       "       [   0,    1,    2,  970,    1,   19,    0,    7,    7,    3],\n",
       "       [   0,    7,    0,    0,  944,    0,    3,    5,    1,   22],\n",
       "       [   1,    1,    0,   12,    2,  860,    5,    1,    6,    4],\n",
       "       [   4,    2,    0,    0,    3,    5,  944,    0,    0,    0],\n",
       "       [   0,   14,    6,    2,    4,    0,    0,  992,    0,   10],\n",
       "       [   6,    1,    3,   14,    5,   13,    3,    4,  920,    5],\n",
       "       [   2,    5,    1,    6,   10,    5,    1,   11,    1,  967]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check confusion matrix kNN\n",
    "confusion_matrix(y_test, knn_predictions_test, labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 978,    0,    0,    0,    0,    0,    0,    1,    1,    0],\n",
       "       [   0, 1134,    0,    1,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    1, 1030,    0,    0,    0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0, 1007,    0,    2,    0,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,  978,    0,    1,    0,    0,    3],\n",
       "       [   1,    0,    0,    6,    0,  882,    1,    0,    1,    1],\n",
       "       [   3,    2,    1,    0,    1,    4,  947,    0,    0,    0],\n",
       "       [   0,    1,    6,    0,    0,    0,    0, 1019,    1,    1],\n",
       "       [   2,    0,    3,    2,    0,    1,    0,    0,  963,    3],\n",
       "       [   0,    0,    1,    0,    4,    1,    0,    1,    1, 1001]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check confusion matrix NN \n",
    "confusion_matrix(y_test, model.predict_classes(X_test), labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CBR model to disk\n",
    "pickle.dump(knn_clf, open('k-nn_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Keras Models to disk\n",
    "model.save(\"NN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataframes\n",
    "np.save(\"X_train\", X_train)\n",
    "np.save(\"X_test\", X_test)\n",
    "np.save(\"y_train\", y_train)\n",
    "np.save(\"y_test\", y_test)\n",
    "\n",
    "np.save(\"knn_X_train\", knn_X_train)\n",
    "np.save(\"knn_X_test\", knn_X_test)\n",
    "\n",
    "np.save(\"oh_y_train\", oh_y_train)\n",
    "np.save(\"oh_y_test\", oh_y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
