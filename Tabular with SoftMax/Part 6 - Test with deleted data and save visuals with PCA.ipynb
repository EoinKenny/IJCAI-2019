{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Test Case Retrieval With Local Methods Using Deleted Data\n",
    "\n",
    "Also save Data for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "# My own algorithms\n",
    "from Weighted_KNN_Classifier import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_df.csv\")\n",
    "feature_names = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"NN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_grad_LIME = np.load(\"X_train_grad_LIME.npy\")\n",
    "X_test_grad_LIME = np.load(\"X_test_grad_LIME.npy\")\n",
    "\n",
    "X_train_intgrad = np.load(\"X_train_intgrad.npy\")\n",
    "X_test_intgrad = np.load(\"X_test_intgrad.npy\")\n",
    "X_train_deeplift = np.load(\"X_train_deeplift.npy\")\n",
    "X_test_deeplift = np.load(\"X_test_deeplift.npy\")\n",
    "X_train_lrp = np.load(\"X_train_lrp.npy\")\n",
    "X_test_lrp = np.load(\"X_test_lrp.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Outlier Data for Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_idx = list()\n",
    "for i in range(len(X_train)):\n",
    "    if y_train[i] != model.predict_classes(np.array([X_train[i]]))[0]:\n",
    "        del_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify shape for next loop\n",
    "y_train = np.array([y_train]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_modify = [X_train, y_train, X_train_grad_LIME,\n",
    "             X_train_intgrad, X_train_deeplift, X_train_lrp]\n",
    "\n",
    "modified = list()\n",
    "for i in range(len(to_modify)):\n",
    "    matrix = deepcopy(to_modify[i].tolist())\n",
    "    for index in sorted(del_idx, reverse=True):\n",
    "        del matrix[index]\n",
    "    modified.append(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['X_train_del', 'y_train_del', 'X_train_grad_LIME_del',\n",
    "         'X_train_intgrad_del', 'X_train_deeplift_del', 'X_train_lrp_del']\n",
    "\n",
    "for i in range(len(names)):\n",
    "    matrix = np.array(modified[i])\n",
    "    name = names[i]\n",
    "    # for y_train\n",
    "    if i == 1:\n",
    "        matrix = matrix.T[0]\n",
    "    np.save(name, matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train_del.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train_del.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "X_train_grad_LIME = np.load(\"X_train_grad_LIME_del.npy\")\n",
    "X_train_intgrad = np.load(\"X_train_intgrad_del.npy\")\n",
    "X_train_deeplift = np.load(\"X_train_deeplift_del.npy\")\n",
    "X_train_lrp = np.load(\"X_train_lrp_del.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Global Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_weights = np.load('connection_weights.npy').item()\n",
    "garsons_weights = np.load('garsons_weights.npy').item()\n",
    "sensitivity_weights = np.load('sensitivity_weights.npy').item()\n",
    "perturb_weights = np.load('perturb_weights.npy').item()\n",
    "global_weights = [perturb_weights, sensitivity_weights, garsons_weights, connection_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_weights = []\n",
    "for i in range(len(global_weights)):\n",
    "    weights = global_weights[i]\n",
    "    weight_array = list()\n",
    "    for j in range(len(feature_names)):\n",
    "        if feature_names[j] in weights:\n",
    "            weight_array.append(weights[feature_names[j]]) \n",
    "    final_weights.append(weight_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(final_weights)):\n",
    "    for j in range(len(final_weights[i])):\n",
    "        final_weights[i][j] = abs(final_weights[i][j])\n",
    "final_weights = np.array(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=k, algorithm=\"brute\") \n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy Test: 0.8368857312018946\n",
      "k-NN Accuracy Test: 0.7079632918886916\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn_clf.predict(X_test)\n",
    "nn_pred = model.predict_classes(X_test)\n",
    "print(\"NN Accuracy Test:\", accuracy_score(y_test, nn_pred))\n",
    "print(\"k-NN Accuracy Test:\", accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Global Searches: k = 1\n",
      "=====================================\n",
      "Perturbation:  0.7867081113084665\n",
      "[[  69  209  351]\n",
      " [  43 1154  429]\n",
      " [  57  352 4092]]\n",
      " \n",
      "Agreement: 0.8453226761397277\n",
      " \n",
      "-------------------------------------\n",
      "Sensitivity:  0.7867081113084665\n",
      "[[  72  209  348]\n",
      " [  45 1154  427]\n",
      " [  57  355 4089]]\n",
      " \n",
      "Agreement: 0.8457667258732978\n",
      " \n",
      "-------------------------------------\n",
      "Garson's Algorithm:  0.7864120781527532\n",
      "[[  74  206  349]\n",
      " [  39 1151  436]\n",
      " [  49  364 4088]]\n",
      " \n",
      "Agreement: 0.8357015985790408\n",
      " \n",
      "-------------------------------------\n",
      "Connection Weights:  0.7504440497335702\n",
      "[[  40  240  349]\n",
      " [  45 1055  526]\n",
      " [  45  481 3975]]\n",
      " \n",
      "Agreement: 0.8069863824748372\n",
      " \n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================================\")\n",
    "print(\"Global Searches: k =\", k)\n",
    "print(\"=====================================\")\n",
    "for i in range(len(final_weights)):\n",
    "    if i == 0:\n",
    "        technique = \"Perturbation\"\n",
    "    elif i == 1:\n",
    "        technique = \"Sensitivity\"\n",
    "    elif i == 2:\n",
    "        technique = \"Garson's Algorithm\"\n",
    "    elif i == 3:\n",
    "        technique = \"Connection Weights\"\n",
    "    clf = GlobalWeightedKNN()\n",
    "    clf.fit(X_train, y_train, k=k, weights=final_weights[i])\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(technique + \": \", accuracy_score(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions, labels=None, sample_weight=None))\n",
    "    print(\" \")\n",
    "    right = 0\n",
    "    for i in range(len(nn_pred)):\n",
    "        if predictions[i] == nn_pred[i]:\n",
    "            right += 1\n",
    "    print(\"Agreement:\", right/len(nn_pred))\n",
    "    print(\" \")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Local Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "k-NN*\n",
      "==================================================\n",
      "NN Lables Accuracy: 0.7079632918886916\n",
      "[[  55  208  366]\n",
      " [  51  858  717]\n",
      " [  51  580 3870]]\n",
      " \n",
      "Agreement: 0.7538484310242747\n",
      "==================================================\n",
      "C-DeepLIFT\n",
      "==================================================\n",
      "NN Lables Accuracy: 0.8368857312018946\n",
      "[[ 112  219  298]\n",
      " [  45 1309  272]\n",
      " [  56  212 4233]]\n",
      " \n",
      "Agreement: 1.0\n",
      "==================================================\n",
      "C-Integraded Gradients\n",
      "==================================================\n",
      "NN Lables Accuracy: 0.8368857312018946\n",
      "[[ 112  219  298]\n",
      " [  45 1309  272]\n",
      " [  56  212 4233]]\n",
      " \n",
      "Agreement: 1.0\n",
      "==================================================\n",
      "C-LRP\n",
      "==================================================\n",
      "NN Lables Accuracy: 0.8368857312018946\n",
      "[[ 112  219  298]\n",
      " [  45 1309  272]\n",
      " [  57  211 4233]]\n",
      " \n",
      "Agreement: 0.9998519834221433\n"
     ]
    }
   ],
   "source": [
    "techniques = [[\"k-NN*\", X_train, X_test],\n",
    "              [\"C-DeepLIFT\", X_train_deeplift, X_test_deeplift],\n",
    "              [\"C-Integraded Gradients\", X_train_intgrad, X_test_intgrad],\n",
    "              [\"C-LRP\", X_train_lrp, X_test_lrp]]\n",
    "\n",
    "for item in techniques:\n",
    "    technique = item[0]\n",
    "    train = item[1]\n",
    "    test = item[2]\n",
    "    print(\"==================================================\")\n",
    "    print(technique)\n",
    "    print(\"==================================================\")\n",
    "    kNN = KNeighborsClassifier(n_neighbors=k, algorithm=\"brute\") \n",
    "    kNN.fit(train, y_train)\n",
    "    knn_predictions_test = kNN.predict(test)\n",
    "    print(\"NN Lables Accuracy:\", accuracy_score(y_test, knn_predictions_test))\n",
    "    print(confusion_matrix(y_test, knn_predictions_test, labels=None, sample_weight=None))\n",
    "    print(\" \")\n",
    "    right = 0\n",
    "    for i in range(len(nn_pred)):\n",
    "        if knn_predictions_test[i] == nn_pred[i]:\n",
    "            right += 1\n",
    "    print(\"Agreement:\", right/len(nn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted L2\n",
    "$ Distance = \\sqrt{|W_i|Difference(\\vec{q} - \\vec{x})} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_knn = LocalWeightedKNN()\n",
    "weighted_knn.fit(X_train, y_train, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Local Linear Model\n",
      "==================================================\n",
      "Accuracy:  0.7886323268206039\n",
      "[[  81  247  301]\n",
      " [  43 1199  384]\n",
      " [  56  397 4048]]\n",
      "Time taken: 3559.534276008606\n",
      " \n",
      "Agreement: 0.8518354055654234\n"
     ]
    }
   ],
   "source": [
    "techniques = [[\"Local Linear Model\", X_test_grad_LIME[:, :len(feature_names)]]]\n",
    "\n",
    "for item in techniques:\n",
    "    technique = item[0]\n",
    "    weights = item[1]\n",
    "    print(\"==================================================\")\n",
    "    print(technique)\n",
    "    print(\"==================================================\")\n",
    "    start = time.time()\n",
    "    predictions = list()\n",
    "    for i in range(len(X_test)):            \n",
    "        prediction = weighted_knn.predict(X_test[i], abs(weights[i]))\n",
    "        predictions.append(prediction)\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions, labels=None, sample_weight=None))\n",
    "    print(\"Time taken:\", time.time() - start)\n",
    "    print(\" \")\n",
    "    right = 0\n",
    "    for i in range(len(nn_pred)):\n",
    "        if predictions[i] == nn_pred[i]:\n",
    "            right += 1\n",
    "    print(\"Agreement:\", right/len(nn_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
